METHOD_0 ( ) { org . apache . avro . IDENT_0 . IDENT_1 IDENT_2 = new org . apache . avro . IDENT_0 . IDENT_3 . METHOD_1 ( org . apache . IDENT_4 . test . Person . IDENT_5 ) ; IDENT_2 . put ( "name" , STRING_0 ) ; IDENT_2 . put ( STRING_1 , INT_0 ) ; IDENT_2 . put ( STRING_2 , com . google . common . collect . Lists . newArrayList ( STRING_3 , STRING_4 ) ) ; METHOD_2 ( com . google . common . collect . Lists . newArrayList ( IDENT_2 ) , Person . IDENT_6 . ) ; org . apache . IDENT_4 . IDENT_7 pipeline = new org . apache . IDENT_4 . impl . spark . METHOD_3 ( STRING_5 , STRING_6 ) ; org . apache . IDENT_4 . IDENT_8 < org . apache . IDENT_4 . test . Person > IDENT_9 = pipeline . read ( org . apache . IDENT_4 . io . IDENT_10 . METHOD_4 ( METHOD_4 . getAbsolutePath ( ) , org . apache . IDENT_4 . types . avro . IDENT_11 . records ( org . apache . IDENT_4 . test . Person . class ) ) ) ; java . io . File IDENT_12 = IDENT_13 . METHOD_5 ( STRING_7 ) ; org . apache . IDENT_4 . IDENT_14 IDENT_15 = new org . apache . IDENT_4 . io . IDENT_16 . METHOD_6 ( IDENT_12 . getAbsolutePath ( ) ) ; pipeline . write ( IDENT_9 , IDENT_15 ) ; pipeline . run ( ) ; org . apache . IDENT_4 . test . Person person = IDENT_9 . METHOD_7 ( ) . iterator ( ) . next ( ) ; org . apache . hadoop . fs . Path IDENT_17 = new org . apache . hadoop . fs . Path ( new java . io . File ( IDENT_12 , STRING_8 ) . getPath ( ) ) ; org . apache . IDENT_16 . avro . IDENT_18 < org . apache . IDENT_4 . test . Person > reader = new org . apache . IDENT_16 . avro . IDENT_18 < org . apache . IDENT_4 . test . Person > ( IDENT_17 ) ; try { org . apache . IDENT_4 . test . Person IDENT_19 = reader . read ( ) ; "<AssertPlaceHolder>" ; } finally { reader . close ( ) ; pipeline . METHOD_8 ( ) ; } } getPath ( ) { return path ; }
org . junit . Assert . assertThat ( IDENT_19 , org . hamcrest . core . Is . is ( person ) ) 