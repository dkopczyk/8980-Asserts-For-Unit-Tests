METHOD_0 ( ) { org . apache . hadoop . hive . IDENT_0 . exec . spark . status . impl . IDENT_1 IDENT_2 = mock ( org . apache . hadoop . hive . IDENT_0 . exec . spark . status . impl . IDENT_1 . class ) ; when ( IDENT_2 . METHOD_1 ( ) ) . thenReturn ( IDENT_3 . IDENT_4 ) ; when ( IDENT_2 . METHOD_2 ( ) ) . thenReturn ( true ) ; org . apache . hadoop . hive . conf . IDENT_5 IDENT_6 = new org . apache . hadoop . hive . conf . METHOD_3 ( ) ; org . apache . hadoop . hive . IDENT_0 . session . IDENT_7 . start ( IDENT_6 ) ; org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_8 IDENT_9 = new org . apache . hadoop . hive . IDENT_0 . exec . spark . status . METHOD_4 ( IDENT_6 , IDENT_2 ) ; "<AssertPlaceHolder>" ; } METHOD_5 ( ) { boolean IDENT_10 = false ; boolean IDENT_11 = false ; int IDENT_12 = 0 ; org . apache . spark . IDENT_13 IDENT_14 = null ; java . util . Map < org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_15 , org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_16 > IDENT_17 = null ; IDENT_18 . METHOD_6 ( org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_19 , IDENT_20 . IDENT_21 ) ; IDENT_18 . METHOD_6 ( org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_19 , IDENT_20 . IDENT_22 ) ; IDENT_23 = java . lang . System . currentTimeMillis ( ) ; while ( true ) { try { org . apache . spark . IDENT_13 state = IDENT_24 . METHOD_7 ( ) ; if ( org . apache . hadoop . hive . IDENT_0 . exec . spark . status . LOG . METHOD_8 ( ) ) { IDENT_25 . METHOD_9 ( ( STRING_0 + state ) ) ; } if ( state == null ) { long IDENT_26 = ( ( java . lang . System . currentTimeMillis ( ) ) - ( IDENT_23 ) ) / 1000 ; if ( IDENT_26 > ( IDENT_27 ) ) { IDENT_25 . METHOD_10 ( ( ( STRING_1 + IDENT_26 ) + STRING_2 ) ) ; IDENT_25 . METHOD_10 ( ( STRING_3 + state ) ) ; IDENT_10 = false ; IDENT_11 = true ; IDENT_12 = 2 ; break ; } } else if ( ( state != IDENT_14 ) || ( state == ( org . apache . spark . IDENT_13 . IDENT_28 ) ) ) { IDENT_14 = state ; java . util . Map < org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_15 , org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_16 > IDENT_29 = IDENT_24 . METHOD_11 ( ) ; switch ( state ) { case IDENT_28 : if ( ! IDENT_10 ) { IDENT_18 . METHOD_12 ( org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_19 , IDENT_20 . IDENT_22 ) ; IDENT_25 . METHOD_9 ( ( ( STRING_4 8 + ( IDENT_24 . METHOD_13 ( ) ) ) + STRING_4 5 ) ) ; for ( int IDENT_30 : IDENT_24 . METHOD_14 ( ) ) { IDENT_25 . METHOD_9 ( java . lang . Integer . toString ( IDENT_30 ) ) ; } IDENT_25 . METHOD_9 ( ( ( STRING_5 + ( IDENT_24 . METHOD_13 ( ) ) ) + STRING_6 ) ) ; IDENT_10 = true ; IDENT_25 . METHOD_9 ( ( STRING_4 4 + STRING_4 6 ) ) ; } IDENT_31 . METHOD_15 ( IDENT_29 , IDENT_17 ) ; IDENT_17 = IDENT_29 ; break ; case IDENT_32 : IDENT_31 . METHOD_15 ( IDENT_29 , IDENT_17 ) ; IDENT_17 = IDENT_29 ; double IDENT_33 = ( ( java . lang . System . currentTimeMillis ( ) ) - ( IDENT_23 ) ) / FLOAT_0 ; IDENT_25 . METHOD_9 ( ( STRING_7 + ( java . lang . String . format ( STRING_8 , IDENT_33 ) ) ) ) ; IDENT_10 = false ; IDENT_11 = true ; break ; case IDENT_34 : IDENT_25 . METHOD_10 ( STRING_4 ) ; IDENT_10 = false ; IDENT_11 = true ; IDENT_12 = 3 ; break ; case IDENT_35 : IDENT_25 . METHOD_10 ( STRING_4 2 ) ; IDENT_10 = false ; IDENT_11 = true ; IDENT_12 = 4 ; break ; } } if ( ! IDENT_11 ) { java . lang . Thread . sleep ( IDENT_36 ) ; } } catch ( java . lang . Exception e ) { java . lang . String msg = ( STRING_4 0 + ( org . apache . hadoop . hive . IDENT_0 . exec . IDENT_37 . METHOD_16 ( e ) ) ) + STRING_4 1 ; msg = ( ( STRING_9 + ( IDENT_24 . METHOD_13 ( ) ) ) + STRING_4 3 ) + msg ; org . apache . hadoop . hive . IDENT_0 . exec . spark . status . LOG . error ( msg , e ) ; IDENT_25 . METHOD_10 ( msg , ( STRING_4 7 + ( org . apache . hadoop . util . StringUtils . METHOD_17 ( e ) ) ) ) ; IDENT_12 = 1 ; IDENT_11 = true ; IDENT_24 . METHOD_18 ( e ) ; } finally { if ( IDENT_11 ) { break ; } } } IDENT_18 . METHOD_12 ( org . apache . hadoop . hive . IDENT_0 . exec . spark . status . IDENT_19 , IDENT_20 . IDENT_21 ) ; return IDENT_12 ; }
org . junit . Assert . assertEquals ( IDENT_9 . METHOD_5 ( ) , 3 ) 