METHOD_0 ( ) { int [ ] IDENT_0 = new int [ ] { 5 , 6 , INT_0 , 4 , 7 , 9 , 8 , INT_1 , INT_2 } ; double [ ] IDENT_1 = new double [ ] { - FLOAT_0 , FLOAT_1 , 1.0 , - 2.0 , - FLOAT_2 , - 1.0 , FLOAT_3 , - 1.0 , - FLOAT_4 } ; int [ ] IDENT_2 = new int [ ] { 2 , 6 , 1 } ; double [ ] IDENT_3 = new double [ ] { 1.0 , FLOAT_5 , 2.0 } ; int [ ] IDENT_4 = new int [ ] { 4 , 6 , 1 } ; double [ ] IDENT_5 = new double [ ] { FLOAT_6 , FLOAT_7 , FLOAT_5 } ; int [ ] IDENT_6 = new int [ ] { 4 , 1 , 2 } ; double [ ] IDENT_7 = new double [ ] { FLOAT_8 , FLOAT_1 , FLOAT_9 } ; org . apache . spark . api . java . IDENT_8 < org . apache . spark . sql . IDENT_9 > IDENT_10 = IDENT_11 . METHOD_1 ( java . util . Arrays . asList ( org . apache . spark . sql . IDENT_12 . create ( FLOAT_4 , FLOAT_2 , new org . apache . spark . IDENT_13 . linalg . METHOD_2 ( 20 , IDENT_0 , IDENT_1 ) ) , org . apache . spark . sql . IDENT_12 . create ( FLOAT_2 , FLOAT_0 , new org . apache . spark . IDENT_13 . linalg . METHOD_2 ( 20 , IDENT_2 , IDENT_3 ) ) , org . apache . spark . sql . IDENT_12 . create ( FLOAT_0 , FLOAT_0 , new org . apache . spark . IDENT_13 . linalg . METHOD_2 ( 20 , IDENT_4 , IDENT_5 ) ) , org . apache . spark . sql . IDENT_12 . create ( FLOAT_10 , FLOAT_0 , new org . apache . spark . IDENT_13 . linalg . METHOD_2 ( 20 , IDENT_6 , IDENT_7 ) ) ) ) ; org . apache . spark . sql . types . IDENT_14 schema = new org . apache . spark . sql . types . METHOD_3 ( new org . apache . spark . sql . types . IDENT_15 [ ] { new org . apache . spark . sql . types . METHOD_4 ( STRING_0 , org . apache . spark . sql . types . IDENT_16 . IDENT_17 , false , org . apache . spark . sql . types . IDENT_18 . empty ( ) ) , new org . apache . spark . sql . types . METHOD_4 ( STRING_1 , org . apache . spark . sql . types . IDENT_16 . IDENT_17 , false , org . apache . spark . sql . types . IDENT_18 . empty ( ) ) , new org . apache . spark . sql . types . METHOD_4 ( STRING_2 , new org . apache . spark . IDENT_13 . linalg . METHOD_5 ( ) , false , org . apache . spark . sql . types . IDENT_18 . empty ( ) ) } ) ; org . apache . spark . sql . IDENT_19 IDENT_20 = IDENT_21 . METHOD_6 ( IDENT_10 , schema ) ; org . apache . spark . IDENT_22 . feature . IDENT_23 IDENT_24 = new org . apache . spark . IDENT_22 . feature . METHOD_7 ( ) . METHOD_8 ( STRING_2 ) . METHOD_9 ( STRING_3 ) ; byte [ ] IDENT_25 = com . IDENT_26 . IDENT_27 . IDENT_22 . IDENT_28 . IDENT_29 . METHOD_10 ( IDENT_24 , null ) ; com . IDENT_26 . IDENT_27 . IDENT_22 . IDENT_30 . IDENT_31 IDENT_30 = com . IDENT_26 . IDENT_27 . IDENT_22 . IDENT_32 . IDENT_33 . METHOD_11 ( IDENT_25 ) ; org . apache . spark . sql . IDENT_9 [ ] IDENT_34 = IDENT_24 . transform ( IDENT_20 ) . METHOD_12 ( STRING_0 ) . select ( STRING_0 , STRING_1 , STRING_2 , STRING_3 ) . collect ( ) ; for ( org . apache . spark . sql . IDENT_9 row : IDENT_34 ) { java . util . Map < java . lang . String , java . lang . Object > data = new java . util . HashMap ( ) ; data . put ( IDENT_24 . METHOD_13 ( ) , ( ( org . apache . spark . IDENT_13 . linalg . METHOD_2 ) ( row . get ( 2 ) ) ) . toArray ( ) ) ; IDENT_30 . transform ( data ) ; double [ ] output = ( ( double [ ] ) ( data . get ( IDENT_24 . METHOD_14 ( ) ) ) ) ; "<AssertPlaceHolder>" ; } } transform ( com . IDENT_26 . IDENT_27 . IDENT_22 . IDENT_30 . Map ) { java . lang . String IDENT_35 = ( ( java . lang . String ) ( input . get ( IDENT_36 . METHOD_15 ( ) . iterator ( ) . next ( ) ) ) ) ; input . put ( IDENT_36 . METHOD_16 ( ) . iterator ( ) . next ( ) , METHOD_17 ( IDENT_35 ) ) ; }
org . junit . Assert . assertArrayEquals ( output , ( ( org . apache . spark . IDENT_13 . linalg . METHOD_2 ) ( row . get ( 3 ) ) ) . toArray ( ) , 0.0 ) 