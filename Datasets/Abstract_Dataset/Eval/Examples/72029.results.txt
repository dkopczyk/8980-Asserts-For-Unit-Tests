METHOD_0 ( ) { org . apache . spark . sql . types . IDENT_0 schema = METHOD_1 ( new org . apache . spark . sql . types . IDENT_1 [ ] { METHOD_2 ( STRING_0 0 , com . IDENT_2 . IDENT_3 . IDENT_4 . adapter . IDENT_5 , false ) , METHOD_2 ( STRING_0 2 , com . IDENT_2 . IDENT_3 . IDENT_4 . adapter . IDENT_6 , false ) , METHOD_2 ( STRING_1 , com . IDENT_2 . IDENT_3 . IDENT_4 . adapter . IDENT_7 , false ) } ) ; org . apache . spark . sql . IDENT_8 < org . apache . spark . sql . IDENT_9 > IDENT_10 = spark . METHOD_3 ( java . util . Arrays . asList ( METHOD_4 ( 0L , STRING_2 , 1.0 ) , METHOD_4 ( 1L , STRING_0 , 0.0 ) , METHOD_4 ( INT_0 , STRING_3 , 1.0 ) , METHOD_4 ( INT_1 , STRING_4 , 0.0 ) ) , schema ) ; org . apache . spark . IDENT_4 . feature . IDENT_11 IDENT_12 = new org . apache . spark . IDENT_4 . feature . METHOD_5 ( ) . METHOD_6 ( STRING_0 2 ) . METHOD_7 ( STRING_0 4 ) . METHOD_8 ( STRING_0 1 ) . METHOD_9 ( true ) . METHOD_10 ( false ) ; org . apache . spark . IDENT_4 . feature . IDENT_13 IDENT_14 = new org . apache . spark . IDENT_4 . feature . METHOD_11 ( ) . METHOD_12 ( 1000 ) . METHOD_6 ( IDENT_12 . METHOD_13 ( ) ) . METHOD_7 ( STRING_0 5 ) ; org . apache . spark . IDENT_4 . IDENT_15 . IDENT_16 IDENT_17 = new org . apache . spark . IDENT_4 . IDENT_15 . METHOD_14 ( ) . METHOD_15 ( 10 ) . METHOD_16 ( FLOAT_0 ) ; org . apache . spark . IDENT_4 . IDENT_18 pipeline = new org . apache . spark . IDENT_4 . METHOD_17 ( ) . METHOD_18 ( new org . apache . spark . IDENT_4 . IDENT_19 [ ] { IDENT_12 , IDENT_14 , IDENT_17 } ) ; org . apache . spark . IDENT_4 . IDENT_20 IDENT_21 = pipeline . METHOD_19 ( IDENT_10 ) ; byte [ ] IDENT_22 = com . IDENT_2 . IDENT_3 . IDENT_4 . IDENT_23 . IDENT_24 . METHOD_20 ( IDENT_21 ) ; System . out . println ( new java . lang . String ( IDENT_22 ) ) ; com . IDENT_2 . IDENT_3 . IDENT_4 . IDENT_25 . IDENT_26 IDENT_25 = com . IDENT_2 . IDENT_3 . IDENT_4 . IDENT_27 . IDENT_28 . METHOD_21 ( IDENT_22 ) ; org . apache . spark . sql . types . IDENT_0 IDENT_29 = METHOD_1 ( new org . apache . spark . sql . types . IDENT_1 [ ] { METHOD_2 ( STRING_0 0 , com . IDENT_2 . IDENT_3 . IDENT_4 . adapter . IDENT_5 , false ) , METHOD_2 ( STRING_0 2 , com . IDENT_2 . IDENT_3 . IDENT_4 . adapter . IDENT_6 , false ) } ) ; org . apache . spark . sql . IDENT_8 < org . apache . spark . sql . IDENT_9 > IDENT_30 = spark . METHOD_3 ( java . util . Arrays . asList ( METHOD_4 ( INT_2 , STRING_5 ) , METHOD_4 ( INT_3 , STRING_6 ) , METHOD_4 ( INT_4 , STRING_7 ) , METHOD_4 ( INT_5 , STRING_8 ) ) , IDENT_29 ) ; java . util . List < org . apache . spark . sql . IDENT_9 > IDENT_31 = IDENT_21 . transform ( IDENT_30 ) . select ( STRING_0 0 , STRING_0 2 , STRING_9 , STRING_0 3 ) . METHOD_22 ( ) ; for ( org . apache . spark . sql . IDENT_9 r : IDENT_31 ) { System . out . println ( r ) ; double IDENT_32 = r . METHOD_23 ( 3 ) ; java . util . Map < java . lang . String , java . lang . Object > data = new java . util . HashMap < java . lang . String , java . lang . Object > ( ) ; data . put ( STRING_0 2 , r . getString ( 1 ) ) ; IDENT_25 . transform ( data ) ; double IDENT_33 = ( ( double ) ( data . get ( STRING_0 3 ) ) ) ; double IDENT_34 = ( ( double ) ( data . get ( STRING_9 ) ) ) ; "<AssertPlaceHolder>" ; } } transform ( com . IDENT_2 . IDENT_3 . IDENT_4 . IDENT_25 . Map ) { java . lang . String IDENT_35 = ( ( java . lang . String ) ( input . get ( IDENT_36 . METHOD_24 ( ) . iterator ( ) . next ( ) ) ) ) ; input . put ( IDENT_36 . METHOD_25 ( ) . iterator ( ) . next ( ) , METHOD_26 ( IDENT_35 ) ) ; }
org . junit . Assert . assertEquals ( IDENT_32 , IDENT_33 , FLOAT_0 ) 