testPipeline,createStructType,createStructField,createDataFrame,cr,RegexTokenizer,setInputCol,setOutputCol,setPattern,setGaps,setToLowercase,HashingTF,setNumFeatures,getOutputCol,LogisticRegression,setMaxIter,setRegParam,Pipeline,setStages,fit,export,importAndGetTransformer,collectAsList,getDouble,getInputKeys,getOutputKeys,predict,
METHOD_0,METHOD_1,METHOD_2,METHOD_3,METHOD_4,METHOD_5,METHOD_6,METHOD_7,METHOD_8,METHOD_9,METHOD_10,METHOD_11,METHOD_12,METHOD_13,METHOD_14,METHOD_15,METHOD_16,METHOD_17,METHOD_18,METHOD_19,METHOD_20,METHOD_21,METHOD_22,METHOD_23,METHOD_24,METHOD_25,METHOD_26,

StructType,StructField,flipkart,fdp,ml,LongType,StringType,DoubleType,Dataset,Row,trainingData,RegexTokenizer,tokenizer,HashingTF,hashingTF,classification,LogisticRegression,lr,Pipeline,PipelineStage,PipelineModel,sparkPipelineModel,exportedModel,export,ModelExporter,transformer,Transformer,importer,ModelImporter,testSchema,testData,predictions,sparkPipelineOp,exportedPipelineOp,exportedPipelineProb,inp,modelInfo,
IDENT_0,IDENT_1,IDENT_2,IDENT_3,IDENT_4,IDENT_5,IDENT_6,IDENT_7,IDENT_8,IDENT_9,IDENT_10,IDENT_11,IDENT_12,IDENT_13,IDENT_14,IDENT_15,IDENT_16,IDENT_17,IDENT_18,IDENT_19,IDENT_20,IDENT_21,IDENT_22,IDENT_23,IDENT_24,IDENT_25,IDENT_26,IDENT_27,IDENT_28,IDENT_29,IDENT_30,IDENT_31,IDENT_32,IDENT_33,IDENT_34,IDENT_35,IDENT_36,

2L,3L,4L,5L,6L,7L,
INT_0,INT_1,INT_2,INT_3,INT_4,INT_5,




"b d","label","a b c d e spark","spark f g h","hadoop mapreduce","spark i j k","l m n","mapreduce spark","apache hadoop","probability",
STRING_0,STRING_1,STRING_2,STRING_3,STRING_4,STRING_5,STRING_6,STRING_7,STRING_8,STRING_9,

0.01,
FLOAT_0,






















