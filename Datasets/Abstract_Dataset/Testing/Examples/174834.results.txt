METHOD_0 ( ) { java . lang . String IDENT_0 = STRING_0 ; org . apache . hadoop . hbase . filter . IDENT_1 IDENT_2 = new org . apache . hadoop . hbase . filter . METHOD_1 ( STRING_1 ) ; IDENT_2 . METHOD_2 ( new org . apache . hadoop . hbase . filter . METHOD_3 ( IDENT_0 ) ) ; org . apache . hadoop . hbase . filter . IDENT_3 info = new org . apache . hadoop . hbase . filter . METHOD_4 ( IDENT_2 . getName ( ) , null , null , false ) ; org . apache . hadoop . hbase . IDENT_4 . IDENT_5 IDENT_6 = org . apache . hadoop . hbase . IDENT_4 . IDENT_5 . METHOD_5 ( info , org . apache . hadoop . hbase . filter . IDENT_7 . IDENT_8 . METHOD_6 ( ) , org . apache . hadoop . hbase . filter . IDENT_7 . IDENT_8 . METHOD_7 ( ) , IDENT_2 ) ; try { java . util . List < java . lang . String > IDENT_9 = METHOD_8 ( 100 , STRING_2 ) ; java . util . List < java . lang . String > IDENT_10 = METHOD_8 ( INT_0 , STRING_3 ) ; long IDENT_11 = 2 ; java . util . List < org . apache . hadoop . hbase . filter . IDENT_12 > IDENT_13 = new java . util . ArrayList < org . apache . hadoop . hbase . filter . IDENT_12 > ( ) ; java . util . Map < java . lang . String , java . util . List < org . apache . hadoop . hbase . filter . IDENT_12 > > IDENT_14 = new java . util . HashMap < java . lang . String , java . util . List < org . apache . hadoop . hbase . filter . IDENT_12 > > ( ) ; IDENT_14 . put ( STRING_4 , new java . util . ArrayList < org . apache . hadoop . hbase . filter . IDENT_12 > ( ) ) ; IDENT_14 . put ( STRING_5 , new java . util . ArrayList < org . apache . hadoop . hbase . filter . IDENT_12 > ( ) ) ; java . lang . String IDENT_15 = STRING_6 ; for ( java . lang . String row : IDENT_9 ) { org . apache . hadoop . hbase . client . IDENT_16 p = new org . apache . hadoop . hbase . client . METHOD_9 ( org . apache . hadoop . hbase . util . IDENT_17 . METHOD_10 ( row ) ) ; p . METHOD_11 ( false ) ; for ( java . lang . String column : IDENT_10 ) { for ( long IDENT_18 = 1 ; IDENT_18 <= IDENT_11 ; IDENT_18 ++ ) { org . apache . hadoop . hbase . filter . IDENT_12 IDENT_19 = org . apache . hadoop . hbase . filter . IDENT_20 . create ( row , IDENT_0 , column , IDENT_18 , IDENT_15 ) ; p . add ( IDENT_19 ) ; IDENT_13 . add ( IDENT_19 ) ; for ( java . lang . String s : IDENT_14 . METHOD_12 ( ) ) { if ( column . startsWith ( s ) ) { IDENT_14 . get ( s ) . add ( IDENT_19 ) ; } } } } IDENT_6 . put ( p ) ; } org . apache . hadoop . hbase . filter . IDENT_21 filter ; org . apache . hadoop . hbase . client . IDENT_22 IDENT_23 = new org . apache . hadoop . hbase . client . METHOD_13 ( ) ; IDENT_23 . METHOD_14 ( ) ; for ( java . lang . String s : IDENT_14 . METHOD_12 ( ) ) { filter = new org . apache . hadoop . hbase . filter . METHOD_15 ( org . apache . hadoop . hbase . util . IDENT_17 . METHOD_10 ( s ) ) ; IDENT_23 . METHOD_16 ( filter ) ; org . apache . hadoop . hbase . IDENT_4 . IDENT_24 IDENT_25 = IDENT_6 . METHOD_17 ( IDENT_23 ) ; java . util . List < org . apache . hadoop . hbase . filter . IDENT_12 > results = new java . util . ArrayList < org . apache . hadoop . hbase . filter . IDENT_12 > ( ) ; while ( IDENT_25 . next ( results ) ) ; "<AssertPlaceHolder>" ; } } finally { IDENT_6 . close ( ) ; IDENT_6 . METHOD_18 ( ) . METHOD_19 ( ) ; } IDENT_6 . close ( ) ; IDENT_6 . METHOD_18 ( ) . METHOD_19 ( ) ; } get ( java . util . List ) { throw new java . io . IOException ( STRING_7 ) ; }
org . junit . Assert . assertEquals ( IDENT_14 . get ( s ) . size ( ) , results . size ( ) ) 