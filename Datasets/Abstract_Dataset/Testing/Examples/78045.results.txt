METHOD_0 ( ) { org . apache . hadoop . hbase . client . IDENT_0 table = METHOD_1 ( ) ; java . util . List < byte [ ] > keys = java . util . Collections . METHOD_2 ( java . util . Arrays . asList ( com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 10 , INT_0 , 5 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 10 , INT_1 , 5 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 10 , INT_2 , 5 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 10 , INT_3 , 5 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , INT_4 , INT_0 , 7 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , INT_4 , INT_1 , 7 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , INT_4 , INT_2 , 7 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , INT_4 , INT_3 , 7 ) ) ) ; java . util . List < org . apache . hadoop . hbase . client . IDENT_3 > IDENT_4 = new java . util . ArrayList ( ) ; for ( byte [ ] key : keys ) { IDENT_4 . add ( new org . apache . hadoop . hbase . client . METHOD_4 ( key ) . METHOD_5 ( IDENT_5 . IDENT_6 , org . apache . hadoop . hbase . util . IDENT_7 . METHOD_6 ( 0 ) , org . apache . hadoop . hbase . util . IDENT_7 . METHOD_6 ( 0 ) ) ) ; } table . put ( IDENT_4 ) ; org . apache . hadoop . hbase . filter . IDENT_8 filter = new org . apache . hadoop . hbase . filter . METHOD_7 ( com . google . common . collect . ImmutableList . of ( org . apache . hadoop . hbase . util . IDENT_9 . METHOD_8 ( com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 0 , INT_0 , 0 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_9 ( 0 , 1 , 0 , 1 ) ) , org . apache . hadoop . hbase . util . IDENT_9 . METHOD_8 ( com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 0 , INT_1 , 0 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_9 ( 0 , 1 , 0 , 1 ) ) , org . apache . hadoop . hbase . util . IDENT_9 . METHOD_8 ( com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 0 , INT_2 , 0 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_9 ( 0 , 1 , 0 , 1 ) ) , org . apache . hadoop . hbase . util . IDENT_9 . METHOD_8 ( com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_3 ( 5 , 0 , INT_3 , 0 ) , com . google . cloud . IDENT_1 . hbase . IDENT_2 . METHOD_9 ( 0 , 1 , 0 , 1 ) ) ) ) ; org . apache . hadoop . hbase . client . IDENT_10 IDENT_11 = new org . apache . hadoop . hbase . client . METHOD_10 ( ) . METHOD_11 ( filter ) ; java . util . Set < java . lang . String > IDENT_12 = new java . util . HashSet ( keys . size ( ) ) ; for ( byte [ ] key : keys ) { IDENT_12 . add ( METHOD_12 ( key ) ) ; } java . util . Set < java . lang . String > IDENT_13 = new java . util . HashSet ( keys . size ( ) ) ; try ( org . apache . hadoop . hbase . client . IDENT_14 IDENT_15 = table . METHOD_13 ( IDENT_11 ) ) { for ( org . apache . hadoop . hbase . client . Result result : IDENT_15 ) { IDENT_13 . add ( METHOD_12 ( org . apache . hadoop . hbase . IDENT_16 . METHOD_14 ( result . METHOD_15 ( ) [ 0 ] ) ) ) ; } } IDENT_13 . remove ( STRING_0 ) ; "<AssertPlaceHolder>" ; } METHOD_12 ( byte [ ] ) { java . lang . StringBuilder sb = new java . lang . StringBuilder ( STRING_1 ) ; java . lang . String IDENT_17 = "" ; int IDENT_18 = ( bytes . length ) / 4 ; for ( int i = 0 ; i < IDENT_18 ; i ++ ) { sb . append ( IDENT_17 ) . append ( org . apache . hadoop . hbase . util . IDENT_7 . METHOD_16 ( bytes , ( 4 * i ) ) ) ; IDENT_17 = STRING_2 ; } return sb . append ( "]" ) . toString ( ) ; }
org . junit . Assert . assertEquals ( IDENT_12 , IDENT_13 ) 