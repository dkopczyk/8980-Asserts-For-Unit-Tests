METHOD_0 ( ) { io . IDENT_0 . IDENT_1 . IDENT_2 . METHOD_1 ( METHOD_2 ( ) ) ; io . IDENT_0 . metadata . hdfs . entity . IDENT_3 policy = new io . IDENT_0 . metadata . hdfs . entity . METHOD_3 ( STRING_0 , ( ( short ) ( 1 ) ) ) ; io . IDENT_0 . IDENT_1 . IDENT_4 . METHOD_4 ( IDENT_5 , IDENT_6 , IDENT_7 , io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_9 , io . IDENT_0 . IDENT_1 . IDENT_10 , policy ) ; while ( ! ( IDENT_5 . METHOD_5 ( IDENT_6 . METHOD_6 ( ) . getPath ( ) ) . METHOD_7 ( ) ) ) { try { java . lang . Thread . sleep ( 1000 ) ; } catch ( java . lang . IDENT_11 e ) { io . IDENT_0 . IDENT_1 . IDENT_8 . LOG . error ( STRING_1 ) ; } } java . lang . Thread . sleep ( ( 2 * ( conf . METHOD_8 ( IDENT_12 . IDENT_13 , IDENT_12 . IDENT_14 ) ) ) ) ; io . IDENT_0 . metadata . hdfs . entity . IDENT_15 status = IDENT_5 . METHOD_5 ( IDENT_6 . METHOD_6 ( ) . getPath ( ) ) ; org . apache . hadoop . fs . Path IDENT_16 = new org . apache . hadoop . fs . Path ( conf . get ( IDENT_12 . IDENT_17 , IDENT_12 . IDENT_18 ) , status . METHOD_9 ( ) ) ; org . apache . hadoop . fs . IDENT_19 IDENT_20 = IDENT_5 . METHOD_10 ( IDENT_16 ) ; "<AssertPlaceHolder>" ; try { org . apache . hadoop . fs . IDENT_21 in = IDENT_5 . METHOD_11 ( IDENT_16 ) ; byte [ ] IDENT_22 = new byte [ ( ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_23 ) * ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_24 ) ) * ( IDENT_10 ) ] ; in . METHOD_12 ( 0 , IDENT_22 ) ; } catch ( org . apache . hadoop . hdfs . IDENT_25 e ) { io . IDENT_0 . IDENT_1 . IDENT_8 . LOG . error ( STRING_2 , e ) ; org . junit . Assert . fail ( STRING_3 ) ; } int IDENT_26 = new java . util . METHOD_13 ( IDENT_7 ) . METHOD_14 ( ( ( int ) ( ( IDENT_20 . METHOD_15 ( ) ) / ( IDENT_20 . METHOD_16 ( ) ) ) ) ) ; org . apache . hadoop . hdfs . protocol . IDENT_27 IDENT_28 = IDENT_5 . METHOD_17 ( ) . METHOD_18 ( IDENT_16 . METHOD_6 ( ) . getPath ( ) , 0 , Long . MAX_VALUE ) . get ( IDENT_26 ) ; org . apache . hadoop . hdfs . server . IDENT_29 . IDENT_30 . METHOD_19 ( cluster , IDENT_28 ) ; io . IDENT_0 . IDENT_1 . IDENT_8 . LOG . info ( ( STRING_4 + ( IDENT_28 . toString ( ) ) ) ) ; try { org . apache . hadoop . fs . IDENT_21 in = IDENT_5 . METHOD_11 ( IDENT_16 ) ; byte [ ] IDENT_22 = new byte [ ( ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_23 ) * ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_24 ) ) * ( IDENT_10 ) ] ; in . METHOD_12 ( 0 , IDENT_22 ) ; org . junit . Assert . fail ( STRING_5 ) ; } catch ( org . apache . hadoop . hdfs . IDENT_25 e ) { } java . lang . Thread . sleep ( ( ( 2 * ( conf . METHOD_8 ( IDENT_12 . IDENT_13 , IDENT_12 . IDENT_14 ) ) ) + ( 2 * ( conf . METHOD_20 ( IDENT_12 . IDENT_31 , 0 ) ) ) ) ) ; while ( true ) { java . lang . Thread . sleep ( INT_0 ) ; io . IDENT_0 . metadata . hdfs . entity . IDENT_15 IDENT_32 = IDENT_5 . METHOD_5 ( IDENT_6 . METHOD_6 ( ) . getPath ( ) ) ; io . IDENT_0 . IDENT_1 . IDENT_8 . LOG . info ( ( STRING_6 + IDENT_32 ) ) ; if ( ( IDENT_32 . METHOD_21 ( ) ) == ( IDENT_15 . IDENT_33 . IDENT_34 ) ) { break ; } } try { org . apache . hadoop . fs . IDENT_21 in = IDENT_5 . METHOD_11 ( IDENT_16 ) ; byte [ ] IDENT_22 = new byte [ ( ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_23 ) * ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_24 ) ) * ( IDENT_10 ) ] ; in . METHOD_12 ( 0 , IDENT_22 ) ; } catch ( org . apache . hadoop . hdfs . IDENT_25 e ) { org . junit . Assert . fail ( STRING_7 ) ; } } METHOD_15 ( ) { return length ; }
org . junit . Assert . assertEquals ( IDENT_20 . METHOD_15 ( ) , ( ( ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_23 ) * ( io . IDENT_0 . IDENT_1 . IDENT_8 . IDENT_24 ) ) * ( IDENT_10 ) ) ) 