
Doc:
scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.
param: Number of parameters (in the Variable).

Profile:
node name | # parameters
_TFProfRoot (--/5.61m params)
  model (--/5.61m params)
    model/att_seq2seq (--/5.61m params)
      model/att_seq2seq/Variable (1, 1/1 params)
      model/att_seq2seq/decode (--/3.08m params)
        model/att_seq2seq/decode/attention (--/197.38k params)
          model/att_seq2seq/decode/attention/att_keys (--/131.33k params)
            model/att_seq2seq/decode/attention/att_keys/biases (256, 256/256 params)
            model/att_seq2seq/decode/attention/att_keys/weights (512x256, 131.07k/131.07k params)
          model/att_seq2seq/decode/attention/att_query (--/65.79k params)
            model/att_seq2seq/decode/attention/att_query/biases (256, 256/256 params)
            model/att_seq2seq/decode/attention/att_query/weights (256x256, 65.54k/65.54k params)
          model/att_seq2seq/decode/attention/v_att (256, 256/256 params)
        model/att_seq2seq/decode/attention_decoder (--/2.32m params)
          model/att_seq2seq/decode/attention_decoder/decoder (--/2.32m params)
            model/att_seq2seq/decode/attention_decoder/decoder/attention_mix (--/196.86k params)
              model/att_seq2seq/decode/attention_decoder/decoder/attention_mix/biases (256, 256/256 params)
              model/att_seq2seq/decode/attention_decoder/decoder/attention_mix/weights (768x256, 196.61k/196.61k params)
            model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell (--/1.84m params)
              model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0 (--/1.31m params)
                model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/lstm_cell (--/1.31m params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/lstm_cell/bias (1024, 1.02k/1.02k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_0/lstm_cell/kernel (1280x1024, 1.31m/1.31m params)
              model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1 (--/525.31k params)
                model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/lstm_cell (--/525.31k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/lstm_cell/bias (1024, 1.02k/1.02k params)
                  model/att_seq2seq/decode/attention_decoder/decoder/extended_multi_rnn_cell/cell_1/lstm_cell/kernel (512x1024, 524.29k/524.29k params)
            model/att_seq2seq/decode/attention_decoder/decoder/logits (--/284.24k params)
              model/att_seq2seq/decode/attention_decoder/decoder/logits/biases (1106, 1.11k/1.11k params)
              model/att_seq2seq/decode/attention_decoder/decoder/logits/weights (256x1106, 283.14k/283.14k params)
        model/att_seq2seq/decode/target_embedding (--/566.27k params)
          model/att_seq2seq/decode/target_embedding/W (1106x512, 566.27k/566.27k params)
      model/att_seq2seq/encode (--/2.53m params)
        model/att_seq2seq/encode/bidi_rnn_encoder (--/1.57m params)
          model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn (--/1.57m params)
            model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw (--/787.46k params)
              model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/lstm_cell (--/787.46k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/lstm_cell/bias (1024, 1.02k/1.02k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/bw/lstm_cell/kernel (768x1024, 786.43k/786.43k params)
            model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw (--/787.46k params)
              model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/lstm_cell (--/787.46k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/lstm_cell/bias (1024, 1.02k/1.02k params)
                model/att_seq2seq/encode/bidi_rnn_encoder/bidirectional_rnn/fw/lstm_cell/kernel (768x1024, 786.43k/786.43k params)
        model/att_seq2seq/encode/source_embedding (--/957.44k params)
          model/att_seq2seq/encode/source_embedding/W (1870x512, 957.44k/957.44k params)
